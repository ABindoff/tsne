---
title: "Manifold dimension reduction"
author: "Bindoff, A."
date: "31 October 2017"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
library(rgl)
library(Rtsne)
library(ggplot2)
library(geozoo)
knitr::opts_chunk$set(echo = FALSE)
knit_hooks$set(webgl = hook_webgl)
n <- 3000
```

`r n` points are sampled randomly and uniformly from the surface of a torus. We wish to make a 2 dimensional representation of these points such that local structure is preserved, *i.e.* points that are close together should stay together. We colour the points to give a sense of where they belong.  


```{r, webgl = TRUE, warning = F, message = F, hold = T}


X <- torus(p = 3, n = n, radius = c(3,1))
A <- data.frame(X$points)
names(A) <- c("v1", "v2", "v3")
A$v4 <- round(((A$v3+1)/2)*n,0)
A <- dplyr::arrange(A, v3)

cr <- colorRampPalette(c("white", "wheat", "yellow", "coral", "firebrick", "black"))(n)
cr2 <- colorRampPalette(c("white", "wheat", "yellow", "seagreen4", "black"))(n)
with(A, plot3d(v1, v2, v3, type = "s", size = 1, col = cr[v4], aspect = FALSE))
```

The Barnes-Hut t-SNE algorithm attempts to fit a model with fewer dimensions, preserving local structure. The lower-dimensional model looks a lot like an elastic torus was split open and flattened out, kind of like a popped torus-shaped balloon. **Colouring has been changed to make it clear which plots are model output and which are sample data**


```{r, webgl = TRUE}
m1 <- Rtsne(as.matrix(scale(A[,1:3])), dims = 2, initial_dims = 3, perplexity = 200, verbose = F)
B <- data.frame(m1$Y)
B$v4 <- A$v4
B$v4[B$v4 == 0] <- 1
B$col <- cr[B$v4]
B$v3 <- rnorm(n, 0, 0.1)

with(B, plot3d(X1, v3, X2, type = "s", size = 1, col = cr2[v4], aspect = FALSE))
# 
# ggplot(B, aes(x = X1, y = X2, colour = factor(v4))) +
#   geom_point(size = 1) + scale_color_manual(guide = F, values = cr)
```


A fourth dimension is added which has a linear relationship with another dimension (v3 on the plot). We simply add the colour mapping as a fourth dimension, and see if we recover the 3 dimensional structure with the colour mapping in-tact. The columns of the 4 x `r n` matrix have been scaled.  


```{r, webgl = TRUE}

m1 <- Rtsne(as.matrix(scale(A)), dims = 3, initial_dims = 4, perplexity = 400, verbose = F)
B <- data.frame(m1$Y)
B$v4 <- A$v4
B$v4[B$v4 == 0] <- 1

with(B, plot3d(X1, X2, X3, type = "s", size = 1, col = cr2[v4], aspect = FALSE))

```

By setting the `perplexity` hyperparameter very high (400) we haven't allowed the points to cluster too greatly, which has preserved the global structure of this embedding quite well. Recall that the matrix columns were scaled. If the matrix hadn't been scaled, the dimension represented by colour would have dominated under Kullback-Leibler as we will see below,  


```{r, webgl = TRUE}

m1 <- Rtsne(as.matrix(A), dims = 3, initial_dims = 4, perplexity = 20, verbose = F)
B <- data.frame(m1$Y)
B$v4 <- A$v4
B$v4[B$v4 == 0] <- 1

with(B, plot3d(X1, X2, X3, type = "s", size = 1, col = cr2[v4], aspect = FALSE))

```

This doesn't tell us much about v1, v2, or v3. This is because v4 is on the scale [0, 3000], while v1, v2 are on the scale [-4, 4] and v3 is on [-1, 1]. This shows the importance of thinking carefully about the topological space the data occupy and how we measure variables.  

Why do we need a fancy Barnes-Hut t-SNE algorithm to do what other dimension reducing algorithms such as PCA or MDS have been doing for years? We attempt the same fit using classical MDS for comparison -  

```{r, webgl = TRUE}
d <- dist(as.matrix(scale(A)))
m2 <- cmdscale(d, k = 3)

B <- data.frame(m2)
B$v4 <- A$v4
B$v4[B$v4 == 0] <- 1

with(B, plot3d(X1, X2, X3, type = "s", size = 1, col = cr2[v4], aspect = FALSE))
# 

```

This is an excellent representation of both global and local structure.  

To increase the level of difficulty, all linear relationships are removed. Now the fourth dimension has a non-linear relationship with v3 and no correlation with v2 or v1.  


```{r, webgl = TRUE}
A$v4 <- round(abs(A$v3)*n, 0)
with(A, plot3d(v1, v2, v3, type = "s", size = 1, col = cr[v4]), aspect = FALSE)
```


```{r, webgl = TRUE}
m1 <- Rtsne(as.matrix(scale(A)), dims = 3, initial_dims = 4, perplexity = 200, verbose = F)
B <- data.frame(m1$Y)
B$v4 <- A$v4
with(B, plot3d(X1, X2, X3, type = "s", size = 1,  col = cr2[v4]), aspect = TRUE)
```

How well does MDS capture this non-linear relationship?  


```{r, webgl = TRUE}
d <- dist(as.matrix(scale(A)))
m2 <- cmdscale(d, k = 3)

B <- data.frame(m2)
B$v4 <- A$v4

with(B, plot3d(X1, X2, X3, type = "s", size = 1, col = cr2[v4], aspect = TRUE))
# 

```

In an odd way it does represent global structure quite well, but not local structure. For example, the ends (in black) have been twisted back around to each other.  

Add dimension v5 which has a non-linear relationship to v1, v2 & v3, and a linear relationship with v4. 


```{r, webgl = TRUE}
A$v5 <- (A$v1)^3
with(A, plot3d(v1, v2, v5, type = "s", size = 1, col = cr[v4], aspect = TRUE))
with(A, plot3d(v2, v3, v5, type = "s", size = 1, col = cr[v4], aspect = TRUE))
with(A, plot3d(v1, v4, v5, type = "s", size = 1, col = cr[v4], aspect = TRUE))

```

Add dimension v6 which gets weird fast.


```{r, webgl = TRUE, echo = T}
A$v6 <- (A$v2)^2 + sqrt((A$v5-A$v3)^2)
with(A, plot3d(v2, v6, v5, type = "s", size = 1, col = cr[v4]))
with(A, plot3d(v3, v5, v6, type = "s", size = 1, col = cr[v4]))

```

We're up to 6 dimensions, so feasibly we could explore them by looking at every combination (here's another representation by way of example)   

```{r, webgl = TRUE}
with(A, plot3d(v4, v1, v6, type = "s", size = 1, col = cr[v4]))
```

But for every dimension we add, we have *d choose 3* possible spatial representations. If we have 10 dimensions, that's 120 relationships that we can visualise (and if, like I did, you think using colour as a way to represent a fourth dimension will always reduce the solution set, consider that *10 choose 4* = 210...). Of course, some of these dimensions may have no relationships, but in practice, how do we know?  

Setting `perplexity` = 750, the t-SNE algorithm will take a long time to compute the embeddings, but the result is superb. If you take some time to explore all of the plots above, you will see that those shapes are embedded in the dimension-reduced t-SNE plot.  


```{r, webgl = TRUE}
m2 <- Rtsne(as.matrix(scale(A)), dims = 3, initial_dims = 6, perplexity = 750)
B <- data.frame(m2$Y)
B$v4 <- A$v4
# load("dimension_reduction.RData")
with(B, plot3d(X1, X2, X3, type = "s", size = 1,  col = cr2[v4]))
```


Not wishing to disappoint fans of MDS -  

```{r, webgl = TRUE}
d <- dist(as.matrix(scale(A)))
m2 <- cmdscale(d, k = 3)

B <- data.frame(m2)
B$v4 <- A$v4
B$v4[B$v4 == 0] <- 1

with(B, plot3d(X1, X2, X3, type = "s", size = 1, col = cr2[v4], aspect = FALSE))
# 

```

Some of the relationships have been captured astonishingly well.  

